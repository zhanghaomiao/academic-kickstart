---
title: Memory Management
# linktitle: Tips 1-2
toc: true
type: docs
date: "2019-05-05T00:00:00+01:00"
draft: false

menu:
  operating_system:
   parent: Concepts
   weight: 3
# Prev/next pager order (if `docs_section_pager` enabled in `params.toml`)
weight: 2
---


## Background

- Main memory and registers are the **only storage CPU can access directly**
- **Collection of processes** are waiting on disk to be brought into memory and be executed
- Multiple programs are brought into memory to improve resource utilization and response time to users
- A process may be **moved between disk and memory** during its execution
- Multistep processing of a program
  <img src="https://i.loli.net/2019/03/15/5c8b937772940.png" width="30%"/>

### Address Binding

- Address Binding - Compile Time
  - Program is written as symbolic code
  - Compiler translates symbolic code into **absolute code**
  - If starting location changes **(recompile**)
- Address Binding - Load Time
  - Complier translates symbolic code into relocatable code
  - Relocatable code: machine language that can be run from any memory location
  - If starting location changes (reload the code)
- Address Binding - Execution Time
  - Compiler translates symbolic code into logical-address (virtual-address) code
  - Special hardware (MMU memory management unit) is needed for this scheme
  - Most general-purpose OS use this method
- MMU(Memory-management unit)
  - Hardware device that **maps virtual to physical address**
  - The value in the **relocation register is added to every address** generated by a user process at the time it is sent to memory
  <img src="https://i.loli.net/2019/03/15/5c8b998d7bef2.png" width="40%"/>
- Logical VS. Physical Address
  - Logical Address — generated by CPU (a.k.a virtual address)
  - Physical address — seen by the memory module
  - Compile-time & load time address binding (logical address = physical address)
  - Execution-time address binding (logical address $\neq$ physical address)
  - The user program deals with logical addresses; it never sees the real physical addresses

### Dynamic loading

- The entire program doesn't need all memory for it to execute, it's a routine is loaded into memory when it is called
- Better memory-space utilization, unused routine is never loaded, particularly useful when large amounts of code are infrequently used (e.g., error handling code)
- No special support from OS is required implemented through program (library, API calls)
- Dynamic Loading Example in C
  - `dlopen()`: opens a library and prepares it for use
  - `desym()`: looks up the value of a symbol in a given opened library
  - `dlclose()`: close a DL library

```C
#include <dlfcn.h>
int main() {
    double (*cosine)(double);
    void* handle = dlopen("/lib/libm.so.6", RTLD_LAZY);
    cosine = dlsym(handle, "cos");
    printf("%f\n", (*cosine)(2.0)); // load into memory
    dlclose(handle);
} 
```

  <img src="https://i.loli.net/2019/03/15/5c8b9e9388d4f.png" width="30%"/>

### Static/Dynamic Linking

- Static Linking: libraries are combined by the loaded into  the program in-memory image
  - Waste memory: duplicated code
  - Faster during execution time
  <img src="https://i.loli.net/2019/03/15/5c8ba03c16a1b.png" width="30%"/>
- Dynamic Linking: Linking postponed until execution time
  - Only one code copy in memory and shared by everyone
  - A stub is included in the program in-memory image for each lib reference
  - Stub call $\rightarrow$ check if the referred lib is in memory $\rightarrow$ if not, load the lib $\rightarrow$ execute the lib
  - DLL (Dynamic link library) on Windows
    <img src="https://i.loli.net/2019/03/15/5c8ba17ef00e8.png" width="10%"/>

### Swapping

- A process can be swapped out of memory to a **backing store**, and later brought back into memory for continuous execution, also used by **midterm scheduling**, different from context switch
- **Backing store**: a chunk of disk, separated from file system, to provide direct access to these memory images
- Free up memory, roll out, roll in, swap lower-priority process with a higher one
- Swap back memory location
  1. if binding is done at compile / load time, swap back memory address must be same
  2. if binding is done at execution time, swap back memory address can be different
- A process to be swapped == must be idle (不能做I/O)
  - Imagine a process that is waiting for I/O is swapped? 1. Never swap a process with pending I/O 2. I/O operations are done through OS buffers (i.e. a memory space not belongs to any user processes)
- Major part os swap time is transfer time; total transfer time is directly proportional to the amount of memory swapped

## Memory allocation

- Fixed-partition allocation (规划停车场)
  Each process loads into one partition of fixed-size, degree of multi-programming is bounded by the number of partitions
- Variable-size partition
  Hole: block of contiguous free memory, holes of various size are scattered in memory

### Multiple Partition (Variable-size) method

1. First-fit allocate the 1st hole that fits
2. Best-fit allocate the smallest hole that fits (must search through the whole list)
3. Worst-fit allocate the largest hole (must also search through the whole list)
4. First-fit and best-fit better than worst-fit in terms of speed and storage utilization

### Fragmentation (存在零碎的空间)

- external fragmentation
  Total free memory space is big enough to satisfy a request, but is not contiguous, occur in variable-size allocation
- Internal fragmentation
  - Memory that is internal to a partition but is not being used, occur in fixed-partition allocation
- Solution: compaction
  - Shuffle the memory contents to place all free memory together in one large block at execution time
  - Only if binding is done at execution time
  <img src="https://i.loli.net/2019/03/15/5c8ba92f9fed7.png" width="25%"/>

## Non-contiguous memory Allocation - Paging

- Divide physical memory into fixed-sized blocks called **frames**
- Divide logical address space into blocks of the same size called **pages**
- To run a program of n pages, need to find n free frames and load the program
- **keep track of free frames**
- Set up a **page table** to translate logical to physical addresses
- Benefit
  - Allow the physical-address space of a process to be noncontiguous
  - Avoid external fragmentation
  - Limited internal fragmentation
  - Provide **shared memory/pages**

### Page table

- Each entry maps to the base address of a page in physical memory
- A structure maintained by OS for each process
  - page table includes only pages owned by a process
  - A process cannot access memory outside its space
<img src="https://i.loli.net/2019/03/15/5c8baa11b9f0c.png" width="400px"/>

### Address Translation Scheme

- Logical address is divided into two parts
  - Page number (p)
    Use as an index into a page table which contains base address of each page in physical memory, N bits means a process can allocate at most $2^{N}$ pages
  - Page offset(d)
    Combines with base address to define the physical memory address that is sent to the memory unit, N bits means the page size is $2^{N}$
- Physical address = page base address + page offset
- example: If page size is 1KB(2^10) and page 2 maps to frame 5. Given 13 bits logical address: (p=2, d=20), what is physical address?
  $$5*(1KB) + 20 = 1,010,000,000,000 + 0,000,010,100 = 1,010,000,010,100$$
- Figure
  <img src="https://i.loli.net/2019/03/16/5c8c64134af0b.png" width="400px"/>
- total number of pages dose not need to be the same as the total number of frames
- Given 32 bits logical address, 36 bits physical address and 4KB page size, what does it mean?
  - Page table size: $2^{32} / 2^{12} = 2^{20}$ entries
  - Max program memory: $2^{32} = 4GB$
  - Total physical memory size: $2^{36} = 64GB$
  - Number of bits for page number: $2^{20}$ pages $\rightarrow 20$ bits
  - Number of bits for frame number: $2^{24} \text{frames} \rightarrow 2^24$ bits  
  - number of bits for page offset: 4KB page size = $2^{12}$ bytes $\rightarrow 12$ 
- Page / Frame Size
  - Typically power of 2
  - Ranging from 512 bytes to 16 MB/ page, 4KB/8KB page is commonly used
  - Larger page size $\rightarrow$ More space waste
  - page sizes have grown over time , memory, process, data sets have become larger

### Paging Summary

1. Paging helps separate user's view of memory and the actual physical memory
2. User view's memory: one single contiguous space
3. OS maintains a copy of the **page table for each process**
4. OS maintains a frame table for managing physical memory
   1. One entry for each physical frame
   2. Indicate whether a frame is free or allocated
   3. If allocated, to which page of which process or processes

### Implementation of Page Table

1. Page table is kept in memory
2. Page table base register (PTBR) (需要load到MMU的register)
   - The physical memory address of the page table
   - The PTBR value is stored in PCB (Process Control Block)
   - Changing the value of PTBR during **Context-switch**
3. With PTBR, each memory reference results in 2 memory reads, one for the page table and one for the real address
4. The 2-access problem can be solved by, **Translation Look-aside Buffers**(TLB) which is implemented by **Associative memory**
5. Associative Memory
   All memory entries can be accessed **at the same time**, lookup time is O(1), each entry corresponds to an associative register, the number of entries are limited (64 ~ 1024)
   <img src="https://i.loli.net/2019/03/17/5c8da6019d2c1.png" width="400px"/>
   <div class="note info"><p> TLB is a cache for page table shared by all processes </p></div>
6. TLB must be flushed after a context switch, otherwise, TLB entry must has a PID field (address-space identifiers (ASIDs)), the flush method is preferred.
7. Effective Memory-Access Time (EMAT)
   1. $20 ns$ for TLB search
   2. $100 ns$ for memory access
   3. $70%$ TLB hit-ratio
      - $70$ TLB hit-ratio $\text{EMAT} = 0.7\times (20+100) + (1-0.7) \times (20+100+100) = 150ns$
      - $98%$ TLB hit-ration $\text{EMAT} = 0.98\times 120+0.02 \times 220=122ns$

### Memory Protection

1. Each page is associated with a set of **protection bit** in the page table
   <div class="note info"><p>(A bit to define read/write/execution permission)</p></div>
2. Common use : valid-invalid bit
    - Valid: the page/frame is in the process' logical address space, and is thus a legal page
    - Invalid: the page/frame is not in the process' logical address space
    - potential issues: Un-used page entry cause memory-waste, use page table length register(PTLR)
    - Process memory may NOT be on the boundary of a page, memory limit register is still needed
    <img src="https://i.loli.net/2019/03/17/5c8db2c2cdea7.png" width="400px"/>
3. Shared Pages
  Paging allows processes share common code, which must be reentrant
    - Reentrant code (pure code): it never change during execution, text editors, compilers, web servers, etc
    - **Only one copy** of the shared code needs to be kept in physical memory
    - **Two (several) virtual addresses** are mapped to one physical address
    - Process keeps a copy of its own private data and code
    - Shared code must appear in the same location in the logical address space of all processes
<img src="https://i.loli.net/2019/03/17/5c8db414864da.png" width=400px/>

### Page Table Memory Structure

- Page table could be huge and difficult to be loaded
  - 4GB ($2^{32}$) logical address space with 4KB ($2^{12}$) page, needs 1 million $2^{20}$ page table entry
  - Assume each entry need 4 bytes (32 bits), total size = 4MB (MMU 读的时候是需要连续的4MB memory)
  - Need to break it into several smaller page tables, better within  a single page size (i.e. 4KB)
  - Or reduces the total size of page table

#### Hierarchical Paging

- Break up the logical address space into multiple page tables
  - 12-bit offset (d) $\rightarrow$ 4KB($2^{12}$) page size
  - 10-bit outer page number $\rightarrow$ 1K $2^{10}$ page table entries
  - 10-bit inner page number $\rightarrow$ 1K $2^{10}$ page table entries
  <img src="https://i.loli.net/2019/03/17/5c8ddfd25900c.png" width="400px"/>
- Two-level paging example(32-bit address with 4KB ($2^{12}$) page size)
<img src="https://i.loli.net/2019/03/17/5c8dbf784c160.png" width="400px"/>
- example: <img src="https://i.loli.net/2019/04/01/5ca17e7a97138.png" width="400px"/>
- 64-bit Address?
  1. 2 level: 42(p1) + 10 (p2) + 12 (offset), outer table requires $2^{42} \times 4B = 16 {TB}$ contiguous memory
  2. 6 level: $12(p1) + 10(p2) + 10(p3) + 10(p4) + 10 (p5) + 12 (offset)$, needs 6 memory accesses
  <div class = "note info"><p>
      SPAPC(32-bit) and linux use 3-level paging, Motorola 68030 (32-bit) use 4-level paging
  </p></div>

#### Hashed Page Table

- Commonly-used for address > 32 bits
- Virtual page number is hashed into a hash table
- The size of the hash table varies, larger hash  table $\rightarrow$  smaller chains in each entry
- Each entry in the hashed table contains
  - Virtual Page Number, Frame Number, Next Pointer
  - Pointers waster memory
  - Traverse linked list waste time & cause additional memory references
  <img src="https://i.loli.net/2019/03/17/5c8dbdd2409f8.png" width=400px/>
  <div class = "note info"><p> 将 entries group 到一起， 存入连续的空间，MMU一次性读进去，可以减少 LinkedList traverse 的时间</p></div>

#### Inverted Page Table (很少见）

- Maintains NO page table for each process ( 节省 memory 空间）
- Maintains a **frame table** for the whole memory, one entry for each real frame of memory
- Each entry in the frame table has (PID Page number)
- Eliminate the memory needed for page tables but increase memory access time, each access needs to search the whole frame table (use hashing for the frame table)
- Hard to support **shared/page memory**
<img src="https://i.loli.net/2019/03/17/5c8dc1b979f62.png" width="400px"/>

## Segmentation

- Memory-management scheme that supports user view of memory
- A program is a collection of segments. A segment is a logical unit includes following:
    <img src="https://i.loli.net/2019/03/17/5c8dc2e3156bb.png" width="300px"/>

### Segmentation Table

- Logical address: (segmentation #, offset), offset has the same length as physical address
- Maps two-dimensional physical addresses, each table entry has:
  - Base (4 bytes): the start physical address
  - Limit (4 bytes): the length of the segment
- Segment-table base register(STBR), the physical address of the segmentation table
- Segment-table length register (STLR), the number of segments
- example
  <img src="https://i.loli.net/2019/04/01/5ca1834f530a6.png" width="400px"/>

### Segmentation Hardware

1. Limit register is used to check offset length
2. MMU allocate memory by assigning an appropriate base address for each segment (physical address cannot overlap between segments)
   <img src="https://i.loli.net/2019/04/01/5ca1840045b4b.png" width="400px"/>
3. Sharing and Protection
    - Protection bits associated with segments
      - Read-only segment (code)
      - Read-write segments (data, heap, stack)
      - Code sharing occurs at segment level (memory communication, shared library)
      - Share segment by having same base in two segment tables

## Segmentation & paging

- Apply segmentation in logical address space
- Apply Paging in physical address space
  <img src="https://i.loli.net/2019/03/17/5c8dd9bc03335.png" width="400px"/>
  
### Address Translation

- CPU generates logical address
  1. Given to segmentation unit $\rightarrow$ produces liner address
  2. Linear address given to paging unit $\rightarrow$ generates physical address in main memory
- Segmentation and paging units form equivalent of MMU
  <img src="https://i.loli.net/2019/03/17/5c8ddd0a0ca4f.png" width="400px"/>

### Example

- Let the physical memory size is 521B, the page size is 32B and the logical address of a program can have 8 segments. Given a 12 bits hexadecimal logical address "448", translate the address with below page and segment tables
  <img src="https://i.loli.net/2019/03/17/5c8dde36a59f1.png" width="400px"/>
